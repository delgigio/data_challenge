tibble(bmi=rnorm(n = 1000,
mean=mean_bmi,
sd = sd_bmi))
combined_bmi <- bind_rows(tb_train %>% select(bmi) %>% mutate(source='real'), simulatedGauss %>% mutate(source='simulation'))
ggplot(combined_bmi, aes(x = bmi, color = source)) +
geom_density() +
labs(title = "distribution of real BMI  and simulated gaussian",
x = "BMI",
y = "Density") +
theme_minimal()
mean_bmi <- data %>%
summarize(mean(bmi)) %>% pull();
sd_bmi <- data %>%
summarize(sd(bmi)) %>% pull()
simulatedGauss <-
tibble(bmi=rnorm(n = 1000,
mean=mean_bmi,
sd = sd_bmi))
combined_bmi <- bind_rows(data %>% select(bmi) %>% mutate(source='real'), simulatedGauss %>% mutate(source='simulation'))
ggplot(combined_bmi, aes(x = bmi, color = source)) +
geom_density() +
labs(title = "distribution of real BMI  and simulated gaussian",
x = "BMI",
y = "Density") +
theme_minimal()
mean_bmi <- data %>%
summarize(mean(bmi)) %>% pull();
sd_bmi <- data %>%
summarize(sd(bmi)) %>% pull()
simulatedGauss <-
tibble(bmi=rnorm(n = 1000,
mean=mean_bmi,
sd = sd_bmi))
combined_bmi <- bind_rows(data %>% select(bmi) %>% mutate(source='real'), simulatedGauss %>% mutate(source='simulation'))
ggplot(combined_bmi, aes(x = bmi, color = source)) +
geom_density() +
labs(title = "distribution of real BMI  and simulated gaussian",
x = "BMI",
y = "Density") +
theme_minimal()
mean_bmi <- data %>%
summarize(mean(bmi)) %>% pull();
sd_bmi <- data %>%
summarize(sd(bmi)) %>% pull()
simulatedGauss <-
tibble(bmi=rnorm(n = 1000,
mean=mean_bmi,
sd = sd_bmi))
combined_bmi <- bind_rows(data %>% select(bmi) %>% mutate(source='real'), simulatedGauss %>% mutate(source='simulation'))
ggplot(combined_bmi, aes(x = bmi, color = source)) +
geom_density() +
labs(title = "distribution of real BMI  and simulated gaussian",
x = "BMI",
y = "Density") +
theme_minimal()
mean_bmi <- data %>%
summarize(mean(bmi)) %>% pull();
sd_bmi <- data %>%
summarize(sd(bmi)) %>% pull()
simulatedGauss <-
tibble(bmi=rnorm(n = 1000,
mean=mean_bmi,
sd = sd_bmi))
combined_bmi <- bind_rows(data %>% select(bmi) %>% mutate(source='real'), simulatedGauss %>% mutate(source='simulation'))
ggplot(combined_bmi, aes(x = bmi, color = source)) +
geom_density() +
labs(title = "distribution of real BMI  and simulated gaussian",
x = "BMI",
y = "Density") +
theme_minimal()
bmi_stroke <- data %>% filter(stroke==1) %>% select(bmi)
bmi_safe <- data %>% filter(stroke==0) %>% select(bmi)
print(glue("Mean BMI of people who didn't have a stroke: {mean(bmi_stroke$bmi)}"))
print(glue("Mean BMI of people who had a stroke: {mean(bmi_safe$bmi)}"))
bmi_stroke <- data %>% filter(stroke==1) %>% select(bmi)
bmi_safe <- data %>% filter(stroke==0) %>% select(bmi)
print(glue("Mean BMI of people who didn't have a stroke: {mean(bmi_stroke$bmi)}"))
print(glue("Mean BMI of people who had a stroke: {mean(bmi_safe$bmi)}"))
bmi_stroke <- tb_train %>% filter(stroke==1) %>% select(bmi)
bmi_safe <- tb_train %>% filter(stroke==0) %>% select(bmi)
print(glue("Mean BMI of people who didn't have a stroke: {mean(bmi_stroke$bmi)}"))
print(glue("Mean BMI of people who had a stroke: {mean(bmi_safe$bmi)}"))
bmi_stroke <- data %>% filter(stroke==1) %>% select(bmi)
bmi_safe <- data %>% filter(stroke==0) %>% select(bmi)
print(glue("Mean BMI of people who didn't have a stroke: {mean(bmi_stroke$bmi)}"))
print(glue("Mean BMI of people who had a stroke: {mean(bmi_safe$bmi)}"))
t.test(bmi_stroke$bmi, bmi_safe$bmi)
null_hypothesis <- data %>%  specify(response = bmi, explanatory = stroke) %>%  hypothesize(null = "independence")
null_distribution <- null_hypothesis %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "diff in means", order = c(0, 1))
observed_stat <- data %>%  specify(response = bmi, explanatory = stroke) %>%  calculate(stat = "diff in means", order = c(0, 1))
null_distribution %>%  visualize() +  shade_p_value(obs_stat = observed_stat, direction = "two-sided")
p_value <- null_distribution %>%  get_p_value(obs_stat = observed_stat, direction = "two-sided")
p_value
data %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
tb_train %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
data %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
tb_train %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
tb_train %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
data %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
tb_train %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
data %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
tb_train %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
data %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
tb_train %>% ggplot()+geom_boxplot(aes(x=work_type, y=bmi))
data %>% ggplot()+geom_boxplot(aes(x=work_type, y=bmi))
observed_f_statistic <- data %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  calculate(stat = "F")
null_dist <- data %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "F")
null_dist %>%  visualize() +   shade_p_value(observed_f_statistic, direction = "greater")
null_dist %>%  get_p_value(obs_stat = observed_f_statistic, direction = "greater")
data_no_children <- data %>% filter(work_type != "children")
observed_f_statistic <- data_no_children %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  calculate(stat = "F")
null_dist <- data_no_children %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "F")
null_dist %>%  visualize() +   shade_p_value(observed_f_statistic, direction = "greater")
null_dist %>%  get_p_value(obs_stat = observed_f_statistic, direction = "greater")
data_adults <- data %>% filter(work_type != "Never_worked" & work_type != "children")
observed_f_statistic <- data_adults %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  calculate(stat = "F")
null_dist <- data_adults %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "F")
null_dist %>%  visualize() +   shade_p_value(observed_f_statistic, direction = "greater")
null_dist %>%  get_p_value(obs_stat = observed_f_statistic, direction = "greater")
us_logreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
us_logreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
us_logreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
train_withResid <- us_logreg_fit_workflow %>%
extract_fit_engine() %>%
augment()
train_withResid %>%
ggplot()+
geom_point(aes(
x=bmi,
y=.resid))
logreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
# loading useful libraries
suppressWarnings( suppressPackageStartupMessages({
install.packages('themis', quiet = TRUE)
install.packages('randomForest', quiet = TRUE)
install.packages("infer", quiet = TRUE)
install.packages('performance', quiet = TRUE)
install.packages('corrr', quiet = TRUE)
library(rlang)  #  pass string feature names to functions
library(infer)
library(themis)
library(performance) # check if models are valid
library(tidyverse)
library(glue)  # f-strings
library(tidymodels)
library(caret)  # stratified split
library(corrr)   # corr matrix
}))
set.seed(999)
data <- read_csv("./healthcare-dataset-stroke-data.csv", show_col_types =FALSE)
dim(data); colnames(data)
head(data, 5)
length(unique(data$id)); dim(data)[[1]]
data <- select(data, -id)
sapply(data, function(x) sum(x == "N/A"))
data <- data[!apply(data == "N/A", 1, any), ]
sapply(data, function(x) sum(x == "N/A"))
data$bmi <- as.numeric(data$bmi)
data$stroke <- as.factor(data$stroke)
train.index <- createDataPartition(data$stroke, p = 0.75, list = FALSE)
tmp_train <- data[ train.index,]
tb_test  <- data[-train.index,]
train_2.index <- createDataPartition(tmp_train$stroke, p = 0.75, list = FALSE)
tb_val  <- tmp_train[-train_2.index,]
tb_train <- tmp_train[ train_2.index,]
print(glue("Train set shape: ({dim(tb_train)[[1]]}, {dim(tb_train)[[2]]})"))
print(glue("Validation set shape: ({dim(tb_val)[[1]]}, {dim(tb_val)[[2]]})"))
print(glue("Test set shape: ({dim(tb_test)[[1]]}, {dim(tb_test)[[2]]})"))
numeric_columns <- c('age','avg_glucose_level','bmi')
print(summary(select(tb_train, all_of(numeric_columns))))
for (col in numeric_columns) {
p <- ggplot(tb_train, aes(x = !!sym(col))) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
labs(title = glue("PDF of '{col}'"), x = col, y = "Frequency") +
theme_minimal()
print(p)
}
for (col in numeric_columns) {
p <- ggplot(tb_train, aes(x = factor(0), y = !!sym(col))) +
geom_boxplot() +
labs(title=glue('boxplot of {col}'),y = col, x = "") +
theme_minimal()
print(p)
}
for (col in numeric_columns) {
p <- ggplot(tb_train, aes(x = factor(stroke), y = !!sym(col), fill = factor(stroke))) +
geom_boxplot() +
labs(title = glue("Box plot of {col} stratified by stroke"), y = col, x = "Stroke (0 = False, 1 = True)") +
theme_minimal() +
theme(legend.position = "none")
print(p)
}
ggplot(tb_train, aes(x = age, y = avg_glucose_level)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "red") +
labs(title = "age vs avg_glucose_level", x = "age", y = "avg_glucose_level") +
theme_minimal()
tb_train$stroke_num <- as.numeric(tb_train$stroke)
tb_train %>% correlate()
tb_train <- select(tb_train, -stroke_num)
print(table(tb_train$gender))
cat("\n\n")
print(table(tb_train$work_type))
cat("\n\n")
print(table(tb_train$smoking_status))
cat("\n\n")
print(table(tb_train$Residence_type))
work_counts <- tb_train %>%
group_by(work_type) %>%
summarise(count = n())
ggplot(work_counts, aes(x = "", y = count, fill = work_type)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start = 0) +
theme_void() +
labs(title = "Distribution of work_Type", fill = "Work Type")
smoke_counts <- tb_train %>%
group_by(smoking_status) %>%
summarise(count = n())
ggplot(smoke_counts, aes(x = "", y = count, fill = smoking_status)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start = 0) +
theme_void() +
labs(title = "Distribution of smoking_status", fill = "status")
ggplot(data, aes(x = factor(stroke))) +
geom_bar(fill = c("blue", "orange")) +
labs(title = "Distribution of Stroke", x = "Stroke", y = "Count") +
theme_minimal()
# Bar chart for 'residence_type'
ggplot(data, aes(x = factor(Residence_type))) +
geom_bar(fill = c("green", "red")) +
labs(title = "Distribution of Residence Type", x = "Residence Type", y = "Count") +
theme_minimal()
# Bar chart for 'gender'
ggplot(data, aes(x = factor(gender))) +
geom_bar(fill = c("purple", "yellow", "green")) +
labs(title = "Distribution of Gender", x = "Gender", y = "Count") +
theme_minimal()
tb_train %>% group_by(stroke) %>%
summarise(n=n()) %>% mutate(freq=n/sum(n))
stroke_residence_gender_counts <- tb_train %>%
group_by(stroke, Residence_type, gender) %>%
summarise(count = n()) %>%
ungroup()
ggplot(stroke_residence_gender_counts, aes(x = Residence_type, y = count, fill = gender)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~stroke) +
labs(title = "Distribution of Stroke by Residence Type and Gender",
x = "Residence Type",
y = "Count",
fill = "Gender") +
theme_minimal()
base_recipe <- recipe(stroke ~ ., data = tb_train)
stroke_recipe <- base_recipe %>% step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
logreg <- logistic_reg() %>% set_engine('glm')
logreg_workflow <- workflow() %>% add_model(logreg) %>% add_recipe(stroke_recipe)
logreg_fit_workflow <- logreg_workflow %>% fit(tb_train)
logreg_fit_workflow
logreg_fit_workflow %>%
extract_fit_engine %>%
summary()
logreg_valPred <- logreg_fit_workflow %>% augment(tb_val)
logreg_valPred %>% head(1)
yardstick::metrics(logreg_valPred, truth=stroke, estimate=.pred_class)
logreg_valPred %>% group_by(stroke) %>%
summarise(n=n()) %>% mutate(freq=n/sum(n))
logreg_cm <- logreg_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
logreg_cm
yardstick::recall(logreg_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve <- function(prediction_dataset, target) {
auroc <- yardstick::roc_auc(prediction_dataset, {{ target }},.pred_1,event_level = 'second')$.estimate
roc_curve(prediction_dataset, {{ target }},.pred_1,event_level = 'second') %>% autoplot() +   geom_label(aes(x = 0.75, y = 0.25, label = paste("AUROC:", round(auroc, 5))), size = 4, label.size = 0.5)
}
plot_roc_curve(logreg_valPred, 'stroke')
logreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
rand_forest_spec <- rand_forest(mtry = 3) %>%
set_engine('randomForest') %>%
set_mode('classification')
rf <- rand_forest(mtry = 3) %>%
set_engine('randomForest') %>%
set_mode('classification')
rf_workflow <- workflow() %>% add_model(rf) %>% add_recipe(stroke_recipe)
rf_fit_workflow <- rf_workflow %>% fit(tb_train)
rf_valPred <- rf_fit_workflow %>% augment(tb_val)
rf_valPred %>% head(1)
rf_cm <- rf_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
rf_cm
yardstick::recall(rf_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(rf_valPred, 'stroke')
us_stroke_recipe <- stroke_recipe %>% step_downsample(stroke)
logreg <- logistic_reg() %>% set_engine('glm')
us_logreg_workflow <- workflow() %>% add_model(logreg) %>% add_recipe(us_stroke_recipe)
us_logreg_fit_workflow <- us_logreg_workflow %>% fit(tb_train)
us_logreg_fit_workflow
us_logreg_valPred <- us_logreg_fit_workflow %>% augment(tb_val)
us_logreg_valPred %>% head(1)
us_logreg_cm <- us_logreg_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
us_logreg_cm
#us_logreg_trainPred <- us_logreg_fit_workflow %>% augment(tb_train)
#us_logreg_train_cm <- us_logreg_trainPred %>%
# conf_mat(truth=stroke,estimate=.pred_class)
#us_logreg_train_cm
yardstick::recall(us_logreg_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(us_logreg_valPred, 'stroke')
us_rf_workflow <- workflow() %>% add_model(rf) %>% add_recipe(us_stroke_recipe)
us_rf_fit_workflow <- us_rf_workflow %>% fit(tb_train)
us_rf_valPred <- us_rf_fit_workflow %>% augment(tb_val)
us_rf_valPred %>% head(1)
us_rf_cm <- us_rf_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
print(us_rf_cm)
yardstick::recall(us_rf_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(us_rf_valPred, 'stroke')
us_logreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
train_withResid <- us_logreg_fit_workflow %>%
extract_fit_engine() %>%
augment()
train_withResid %>%
ggplot()+
geom_point(aes(
x=bmi,
y=.resid))
# for each feature
logreg_lasso <- logistic_reg(penalty = 39, mixture = 1) %>%
set_engine('glmnet')
# Create the workflow with the logistic regression model and recipe
logreg_lasso_workflow <- workflow() %>%
add_model(logreg_lasso) %>%
add_recipe(stroke_recipe)
# Fit the workflow to the training data
logreg_lasso_fit_workflow <- logreg_lasso_workflow %>%
fit(tb_train)
# Check the fitted workflow
logreg_lasso_fit_workflow
logreg_ridge <- logistic_reg(penalty = 1, mixture = 0) %>%
set_engine('glmnet')
# Create the workflow with the logistic regression model and recipe
logreg_ridge_workflow <- workflow() %>%
add_model(logreg_ridge) %>%
add_recipe(stroke_recipe)
# Fit the workflow to the training data
logreg_ridge_fit_workflow <- logreg_ridge_workflow %>%
fit(data = tb_train)
# Print the fitted workflow to ensure the output is visible
print(logreg_ridge_fit_workflow)
evaluate_model <- function(fit_workflow, validation_set) {
# Perform predictions on the validation set
val_predictions <- fit_workflow %>%
augment(new_data = validation_set)
# Display the first 300 predictions
print(head(val_predictions, 300))
# Calculate and print evaluation metrics
metrics_results <- yardstick::metrics(val_predictions, truth = stroke, estimate = .pred_class)
print(metrics_results)
# Generate and print confusion matrix
cm <- val_predictions %>%
conf_mat(truth = stroke, estimate = .pred_class)
print(cm)
# Calculate and print recall
recall_value <- yardstick::recall(val_predictions, truth = stroke, estimate = .pred_class, event_level = 'second')
print(recall_value)
# Plot the ROC curve
if (any(names(val_predictions) == ".pred_1")) {
roc_data <- roc_curve(val_predictions, truth = stroke, .pred_1, event_level = 'second')
} else if (any(names(val_predictions) == ".pred_0")) {
roc_data <- roc_curve(val_predictions, truth = stroke, .pred_0, event_level = 'second')
} else {
stop("Predicted probability column not found.")
}
roc_plot <- autoplot(roc_data)
print(roc_plot)
}
evaluate_model(rf_fit_workflow, tb_val)
evaluate_model(logreg_lasso_fit_workflow, tb_val)
evaluate_model(logreg_ridge_fit_workflow, tb_val)
tb_train_no_stroke <- select(tb_train, -stroke)
tb_val_no_stroke <- select(tb_val, -stroke)
age_recipe_base <- recipe(age ~ ., data = tb_train_no_stroke)
age_recipe <- age_recipe_base %>% step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
linreg <-  linear_reg() %>% set_engine("lm")
linreg_workflow <- workflow() %>% add_model(linreg) %>% add_recipe(age_recipe)
linreg_fit_workflow <- linreg_workflow %>% fit(tb_train_no_stroke)
linreg_fit_workflow %>% extract_fit_engine() %>% summary()
linreg_trainPred <- linreg_fit_workflow %>% augment(tb_train_no_stroke)
bind_rows(yardstick::rsq(linreg_trainPred, truth=age,estimate=.pred), yardstick::rmse(linreg_trainPred, truth=age,estimate=.pred))
linreg_valPred <- linreg_fit_workflow %>% augment(tb_val_no_stroke)
bind_rows(yardstick::rsq(linreg_valPred, truth=age,estimate=.pred), yardstick::rmse(linreg_valPred, truth=age,estimate=.pred))
linreg_fit_workflow %>%
extract_fit_engine() %>%
check_model()
train_withResid <- linreg_fit_workflow %>%
extract_fit_engine() %>%
augment()
train_withResid %>%
ggplot()+
geom_point(aes(
x=bmi,
y=.resid))
# for each feature
mean_bmi <- data %>%
summarize(mean(bmi)) %>% pull();
sd_bmi <- data %>%
summarize(sd(bmi)) %>% pull()
simulatedGauss <-
tibble(bmi=rnorm(n = 1000,
mean=mean_bmi,
sd = sd_bmi))
combined_bmi <- bind_rows(data %>% select(bmi) %>% mutate(source='real'), simulatedGauss %>% mutate(source='simulation'))
ggplot(combined_bmi, aes(x = bmi, color = source)) +
geom_density() +
labs(title = "distribution of real BMI  and simulated gaussian",
x = "BMI",
y = "Density") +
theme_minimal()
bmi_stroke <- data %>% filter(stroke==1) %>% select(bmi)
bmi_safe <- data %>% filter(stroke==0) %>% select(bmi)
print(glue("Mean BMI of people who didn't have a stroke: {mean(bmi_stroke$bmi)}"))
print(glue("Mean BMI of people who had a stroke: {mean(bmi_safe$bmi)}"))
t.test(bmi_stroke$bmi, bmi_safe$bmi)
null_hypothesis <- data %>%  specify(response = bmi, explanatory = stroke) %>%  hypothesize(null = "independence")
null_distribution <- null_hypothesis %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "diff in means", order = c(0, 1))
observed_stat <- data %>%  specify(response = bmi, explanatory = stroke) %>%  calculate(stat = "diff in means", order = c(0, 1))
null_distribution %>%  visualize() +  shade_p_value(obs_stat = observed_stat, direction = "two-sided")
p_value <- null_distribution %>%  get_p_value(obs_stat = observed_stat, direction = "two-sided")
p_value
data %>%  group_by(work_type) %>% summarise(mean=mean(avg_glucose_level), sd=sd(avg_glucose_level),n=n())
data %>% ggplot()+geom_boxplot(aes(x=work_type, y=bmi))
observed_f_statistic <- data %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  calculate(stat = "F")
null_dist <- data %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "F")
null_dist %>%  visualize() +   shade_p_value(observed_f_statistic, direction = "greater")
null_dist %>%  get_p_value(obs_stat = observed_f_statistic, direction = "greater")
data_no_children <- data %>% filter(work_type != "children")
observed_f_statistic <- data_no_children %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  calculate(stat = "F")
null_dist <- data_no_children %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "F")
null_dist %>%  visualize() +   shade_p_value(observed_f_statistic, direction = "greater")
null_dist %>%  get_p_value(obs_stat = observed_f_statistic, direction = "greater")
data_adults <- data %>% filter(work_type != "Never_worked" & work_type != "children")
observed_f_statistic <- data_adults %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  calculate(stat = "F")
null_dist <- data_adults %>%  specify(bmi~work_type) %>%  hypothesize(null = "independence") %>%  generate(reps = 1000, type = "permute") %>%  calculate(stat = "F")
null_dist %>%  visualize() +   shade_p_value(observed_f_statistic, direction = "greater")
null_dist %>%  get_p_value(obs_stat = observed_f_statistic, direction = "greater")
age_stroke <- tb_train %>% filter(stroke == 1) %>% select(age)
mean_age_stroke <- mean(age_stroke[["age"]])
booStrap_age <- tb_train %>%    specify(response=age) %>%  generate(reps = 1000, type="bootstrap") %>%   calculate(stat="mean")
CI_age <- booStrap_age %>%   get_confidence_interval(point_estimate = mean_age_stroke, level = .95, type='percentile')
CI_age
booStrap_age %>% visualize() + shade_confidence_interval(endpoints = CI_age)+  geom_vline(xintercept = mean_age_stroke, linetype = "dashed")
us_stroke_recipe <- stroke_recipe %>% step_downsample(stroke, ratio = 2)
us_stroke_recipe <- stroke_recipe %>% step_downsample(stroke, under_ratio = 2)
logreg <- logistic_reg() %>% set_engine('glm')
us_logreg_workflow <- workflow() %>% add_model(logreg) %>% add_recipe(us_stroke_recipe)
us_logreg_fit_workflow <- us_logreg_workflow %>% fit(tb_train)
us_logreg_fit_workflow
us_logreg_valPred <- us_logreg_fit_workflow %>% augment(tb_val)
us_logreg_valPred %>% head(1)
us_logreg_cm <- us_logreg_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
us_logreg_cm
yardstick::recall(us_logreg_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(us_logreg_valPred, 'stroke')
us_stroke_recipe <- stroke_recipe %>% step_downsample(stroke, under_ratio = 1.3)
logreg <- logistic_reg() %>% set_engine('glm')
us_logreg_workflow <- workflow() %>% add_model(logreg) %>% add_recipe(us_stroke_recipe)
us_logreg_fit_workflow <- us_logreg_workflow %>% fit(tb_train)
us_logreg_fit_workflow
us_logreg_valPred <- us_logreg_fit_workflow %>% augment(tb_val)
us_logreg_valPred %>% head(1)
us_logreg_cm <- us_logreg_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
us_logreg_cm
yardstick::recall(us_logreg_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(us_logreg_valPred, 'stroke')
us_stroke_recipe <- stroke_recipe %>% step_downsample(stroke, under_ratio = 1.1)
logreg <- logistic_reg() %>% set_engine('glm')
us_logreg_workflow <- workflow() %>% add_model(logreg) %>% add_recipe(us_stroke_recipe)
us_logreg_fit_workflow <- us_logreg_workflow %>% fit(tb_train)
us_logreg_fit_workflow
us_logreg_valPred <- us_logreg_fit_workflow %>% augment(tb_val)
us_logreg_valPred %>% head(1)
us_logreg_cm <- us_logreg_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
us_logreg_cm
yardstick::recall(us_logreg_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(us_logreg_valPred, 'stroke')
us_stroke_recipe <- stroke_recipe %>% step_downsample(stroke, under_ratio = 0.6)
logreg <- logistic_reg() %>% set_engine('glm')
us_logreg_workflow <- workflow() %>% add_model(logreg) %>% add_recipe(us_stroke_recipe)
us_logreg_fit_workflow <- us_logreg_workflow %>% fit(tb_train)
us_logreg_fit_workflow
us_logreg_valPred <- us_logreg_fit_workflow %>% augment(tb_val)
us_logreg_valPred %>% head(1)
us_logreg_cm <- us_logreg_valPred %>%
conf_mat(truth=stroke,estimate=.pred_class)
us_logreg_cm
yardstick::recall(us_logreg_valPred, truth=stroke,estimate=.pred_class,event_level='second')
plot_roc_curve(us_logreg_valPred, 'stroke')
